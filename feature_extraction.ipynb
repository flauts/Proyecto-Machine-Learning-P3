{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:26:07.466472Z",
     "start_time": "2025-06-30T23:26:07.152945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:28:40.830263Z",
     "start_time": "2025-06-30T23:28:40.574248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv('BullyingMultiClase.csv')\n",
    "predict_df = pd.read_csv('BullyingPredict.csv')"
   ],
   "id": "8e2a1c0bcee89e0a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature extraction",
   "id": "8dca5279f208ac93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:28:43.315152Z",
     "start_time": "2025-06-30T23:28:43.311739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists('features'):\n",
    "    os.makedirs('features')"
   ],
   "id": "25fd321db9f39f96",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TF-IDF",
   "id": "4d021d4e24a49838"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:28:47.859396Z",
     "start_time": "2025-06-30T23:28:46.920734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "if not os.path.exists('features/tfidf'):\n",
    "    os.makedirs('features/tfidf')\n",
    "\n",
    "tfidf_folder = \"features/tfidf\""
   ],
   "id": "fcc9ecb2c0f3d839",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:29:06.695291Z",
     "start_time": "2025-06-30T23:29:00.737797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfidf= TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                       ngram_range=(1, 2), stop_words='english', max_features=5000)\n",
    "features_train = tfidf.fit_transform(train_df.text).toarray()\n",
    "labels_train = train_df.label\n",
    "features_predict = tfidf.fit_transform(predict_df.text).toarray()"
   ],
   "id": "25ece46545a63c6d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T23:29:13.425884Z",
     "start_time": "2025-06-30T23:29:08.846629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from joblib import dump\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs(tfidf_folder, exist_ok=True)\n",
    "\n",
    "# Save the TF-IDF vectorizer and features\n",
    "dump(tfidf, os.path.join(tfidf_folder, \"tfidf_vectorizer.joblib\"))\n",
    "dump(features_train, os.path.join(tfidf_folder, \"features_train.joblib\"))\n",
    "dump(labels_train, os.path.join(tfidf_folder, \"labels_train.joblib\"))\n",
    "dump(features_predict, os.path.join(tfidf_folder, \"features_predict.joblib\"))\n"
   ],
   "id": "221f1da396056556",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features/tfidf\\\\features_predict.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BERT_EMBEDDING",
   "id": "f965057cedf879f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not os.path.exists('features/tfidf'):\n",
    "    os.makedirs('features/tfidf')\n",
    "\n",
    "bert_folder = \"features/bert\""
   ],
   "id": "d577ba2d5c05311c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # optional progress bar\n",
    "\n",
    "# 1. Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 2. Load tokenizer and base model (no classification head)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "model = AutoModel.from_pretrained(\"xlm-roberta-base\").to(device)\n",
    "model.eval()  # Turn off dropout, etc.\n",
    "\n",
    "\n",
    "# 3. Define a mean pooling function\n",
    "def mean_pool(last_hidden_state, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "    summed = torch.sum(last_hidden_state * mask, dim=1)\n",
    "    counts = torch.clamp(mask.sum(1), min=1e-9)\n",
    "    return summed / counts  # Shape: [batch_size, 768]\n",
    "\n",
    "\n",
    "# 4. Function to extract features from a list of texts\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def extract_features(texts, batch_size=64):\n",
    "    all_embeddings = []\n",
    "    dataloader = DataLoader(texts, batch_size=batch_size)\n",
    "    for batch in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "        # Tokenize a batch of texts\n",
    "        encoded = tokenizer(batch, padding=True, truncation=True,\n",
    "                            return_tensors=\"pt\", max_length=128)\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded)\n",
    "            embeddings = mean_pool(output.last_hidden_state, encoded[\"attention_mask\"])\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "\n",
    "# 5. Extract features for train data\n",
    "x_train = extract_features(train_df[\"text\"].tolist(), batch_size=256)\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "# 6. Extract features for predict data\n",
    "x_predict = extract_features(predict_df[\"text\"].tolist(), batch_size=256)\n",
    "\n",
    "# 7. Save the features and labels\n",
    "torch.save(x_train, os.path.join(bert_folder, \"x_train.pt\"))\n",
    "torch.save(y_train, os.path.join(bert_folder, \"y_train.pt\"))\n",
    "torch.save(x_predict, os.path.join(bert_folder, \"x_predict.pt\"))\n"
   ],
   "id": "d5b2f870f2109ce7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "50456c8174d39dfd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
