{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T19:35:05.314519Z",
     "start_time": "2025-06-30T19:35:05.311768Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:35:05.669640Z",
     "start_time": "2025-06-30T19:35:05.331339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = pd.read_csv(\"cb_multi_labeled_balanced.csv\")\n",
    "df2 = pd.read_csv(\"cyberbullying_tweets.csv\")\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df1.label.unique())"
   ],
   "id": "63af770f50c89c07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99990, 2)\n",
      "(47692, 2)\n",
      "['ethnicity/race' 'not_cyberbullying' 'religion' 'gender/sexual']\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:37:37.810492Z",
     "start_time": "2025-06-30T19:35:05.691225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df1.label.unique())\n",
    "print(df2.cyberbullying_type.unique())\n",
    "\n",
    "df3 = pd.DataFrame(columns=['text'])\n",
    "for i in df2.index:\n",
    "    if df2.loc[i].cyberbullying_type == \"gender\":\n",
    "        new_row = pd.DataFrame({'text': [df2.loc[i].tweet_text], 'label': ['gender/sexual']})\n",
    "        df1 = pd.concat([df1, new_row], ignore_index=True)\n",
    "    elif df2.loc[i].cyberbullying_type == \"ethnicity\":\n",
    "        new_row = pd.DataFrame({'text': [df2.loc[i].tweet_text], 'label': ['ethnicity/race']})\n",
    "        df1 = pd.concat([df1, new_row], ignore_index=True)\n",
    "    elif df2.loc[i].cyberbullying_type == \"religion\":\n",
    "        new_row = pd.DataFrame({'text': [df2.loc[i].tweet_text], 'label': ['religion']})\n",
    "        df1 = pd.concat([df1, new_row], ignore_index=True)\n",
    "    elif df2.loc[i].cyberbullying_type == \"not_cyberbullying\":\n",
    "        new_row = pd.DataFrame({'text': [df2.loc[i].tweet_text], 'label': ['not_cyberbullying']})\n",
    "        df1 = pd.concat([df1, new_row], ignore_index=True)\n",
    "    else:\n",
    "        new_row = pd.DataFrame({'text': [df2.loc[i].tweet_text]})\n",
    "        df3 = pd.concat([df3, new_row], ignore_index=True)\n"
   ],
   "id": "bef899271db007a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ethnicity/race' 'not_cyberbullying' 'religion' 'gender/sexual']\n",
      "['not_cyberbullying' 'gender' 'religion' 'other_cyberbullying' 'age'\n",
      " 'ethnicity']\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:37:37.879759Z",
     "start_time": "2025-06-30T19:37:37.868665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df1.shape)\n",
    "print(df1.label.unique())\n",
    "print(df3.shape)"
   ],
   "id": "76863a8d1a375f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131867, 2)\n",
      "['ethnicity/race' 'not_cyberbullying' 'religion' 'gender/sexual']\n",
      "(15815, 1)\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:37:39.972867Z",
     "start_time": "2025-06-30T19:37:37.910062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Regex pattern to match emojis and symbols\n",
    "EMOJI_PATTERN = re.compile(\n",
    "    \"[\"\n",
    "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    \"\\U00002500-\\U00002BEF\"  # Chinese characters and lines\n",
    "    \"\\U00002702-\\U000027B0\"\n",
    "    \"\\U0001F900-\\U0001F9FF\"  # supplemental symbols\n",
    "    \"\\U0001FA70-\\U0001FAFF\"  # more supplemental\n",
    "    \"\\u200d\"                 # zero-width joiner\n",
    "    \"\\u2640-\\u2642\"\n",
    "    \"\\u2600-\\u2B55\"\n",
    "    \"\\u23cf\"\n",
    "    \"\\u23e9\"\n",
    "    \"\\u231a\"\n",
    "    \"\\ufe0f\"                 # dingbats\n",
    "    \"\\u3030\"\n",
    "    \"]+\",\n",
    "    flags=re.UNICODE\n",
    ")\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text) or not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"@[A-Za-z0-9_]+\", \"\", text)       # Remove @mentions\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)              # Remove URLs\n",
    "    text = EMOJI_PATTERN.sub(r\"\", text)              # Remove emojis\n",
    "    # Convert hashtags to regular words (remove # but keep content)\n",
    "    text = re.sub(r\"#([A-Za-z0-9_]+)\", r\"\\1\", text)  # #MachineLearning -> MachineLearning\n",
    "\n",
    "    text = re.sub(r\"[^a-z0-9]\", \" \", text)           # Keep alphanumerics\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()         # Normalize whitespace\n",
    "    return text if text else \"empty\"\n",
    "\n",
    "df1[\"text\"] = df1[\"text\"].apply(clean_text)\n",
    "df3[\"text\"] = df3[\"text\"].apply(clean_text)\n"
   ],
   "id": "b26021f2937251a5",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T19:41:03.850685Z",
     "start_time": "2025-06-30T19:41:03.508736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1.to_csv('BullyingMultiClase.csv', index=False)\n",
    "df3.to_csv('BullyingPredict.csv', index=False)"
   ],
   "id": "d4477d3a3d7a1f8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values in df1:\n",
      "Series([], Name: text, dtype: object)\n",
      "\n",
      "Rows with NaN values in df3:\n",
      "Series([], Name: text, dtype: object)\n",
      "Empty strings in df1:\n",
      "Empty DataFrame\n",
      "Columns: [text, label]\n",
      "Index: []\n",
      "\n",
      "Empty strings in df3:\n",
      "Empty DataFrame\n",
      "Columns: [text]\n",
      "Index: []\n",
      "\n",
      "Number of empty strings in df1: 0\n",
      "Number of empty strings in df3: 0\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
